{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.misc import comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Select a 2-class dataset with discrete nD features. This dataset needs to be derived from text documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rf(fn):\n",
    "    data = pd.read_csv(fn, sep=',', header=None, skipinitialspace=True,)\n",
    "    # print 'og data size',data.shape\n",
    "    # print data.head()\n",
    "    x = data.loc[:,1:]\n",
    "    p = x.sum(axis = 1)\n",
    "    data[45] = p\n",
    "    # mdata = data.add(p,axis = 0)\n",
    "    return data\n",
    "\n",
    "\n",
    "# K fold\n",
    "def k_fold(size, k, shuffle = False):\n",
    "    index = np.arange(0,size)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index)\n",
    "    index = np.reshape(index, (k,size/k))\n",
    "    test = []\n",
    "    train = []\n",
    "    for i in range(0,k):\n",
    "        test.append(index[i])\n",
    "        temp = np.delete(index,i,0)\n",
    "        train.append(temp.flatten())\n",
    "    return test, train\n",
    "\n",
    "def getParam(train_data):\n",
    "    xnum = train_data.shape[0]\n",
    "    fnum = train_data.shape[1]-2\n",
    "    # p = train_data[fnum+1]\n",
    "    alfaj = np.zeros((2,fnum))\n",
    "    alfa = np.zeros(2)\n",
    "    # p = np.zeros((2,xnum))\n",
    "    sub = pd.DataFrame\n",
    "    subc = [sub,sub]\n",
    "    for i in range(0,2):\n",
    "        subc[i] = train_data[train_data[0] == i]\n",
    "        x_train = subc[i].loc[:,1:fnum]\n",
    "        ps = subc[i][fnum+1]\n",
    "        p = ps.sum()\n",
    "        alfa[i] = len(x_train)\n",
    "        alfaj[i] = x_train.sum(axis = 0)\n",
    "        alfaj[i] = (alfaj[i]+1)/(alfa[i]*p+2)\n",
    "    # subc0 = train_data[train_data[0] == 0]\n",
    "    # subc1 = train_data[train_data[0] == 1]\n",
    "    # alfa[0] = len(subc0)\n",
    "    # alfa[1] = len(subc1)\n",
    "    # alfaj[0] = subc0.sum(axis = 0) # column sum\n",
    "    # alfaj[1] = subc1.sum(axis = 0)\n",
    "    # p[0] = subc0.sum(axis = 1) # row sum\n",
    "    # p[1] = subc1.sum(axis = 1)\n",
    "    # for i in range(0,2):\n",
    "    #\n",
    "    #     alfaj[i] = (alfaj[i]+1)/(alfa[i]*p[i]+2)\n",
    "    # print 'alfa shape',alfa.shape\n",
    "    # print 'alfaj shape', alfaj.shape\n",
    "    return alfa/xnum, alfaj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) Estimate the model parameters and compute a discriminant function based on the distribution in each class. Make sure to use the Naive Bayes assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:\n",
      "[ 0.5  0.5]\n",
      "Alphaj:\n",
      "[[ 0.00056361  0.00056942  0.00059016  0.00060676  0.00055863  0.00057585\n",
      "   0.0005997   0.00060406  0.00053436  0.00054556  0.00058684  0.00059763\n",
      "   0.00057834  0.00059327  0.00054639  0.00053975  0.00057211  0.00057149\n",
      "   0.00056029  0.00055925  0.00062045  0.00062895  0.00058518  0.00059908\n",
      "   0.00053892  0.00053851  0.0005327   0.00054245  0.00055842  0.00057108\n",
      "   0.00060779  0.00062418  0.00052523  0.0005354   0.00054494  0.00054992\n",
      "   0.00054577  0.00055386  0.00060053  0.0006051   0.00058166  0.0005773\n",
      "   0.00049827  0.00048997]\n",
      " [ 0.00060987  0.0005844   0.00059758  0.00060285  0.00058791  0.00058001\n",
      "   0.00063184  0.00061514  0.00056551  0.0005464   0.00060724  0.00060856\n",
      "   0.00059692  0.0005945   0.00055277  0.000524    0.00059801  0.0005833\n",
      "   0.00057825  0.00055475  0.00064765  0.00063096  0.00058989  0.00058484\n",
      "   0.00049414  0.0004814   0.0005396   0.00051412  0.00054333  0.00052444\n",
      "   0.00062327  0.00063205  0.00054113  0.00055299  0.00056881  0.00055431\n",
      "   0.00057539  0.00055629  0.00058462  0.00056178  0.00055014  0.00053301\n",
      "   0.00045636  0.00044933]]\n",
      "187\n",
      "confusion matrix is \n",
      "[[  64.  108.]\n",
      " [  12.    3.]]\n",
      "result of precision, recall,F-measure, and accuracy are\n",
      "(0.37209302325581395, 0.84210526315789469, 0.5161290322580645, 0.35828877005347592)\n"
     ]
    }
   ],
   "source": [
    "def calcm(x,xa,xaj,pi): # x is an example, xa is the alfa of x's class, xaj is also alfaj of that class. so xa is 1*1, xaj is 1*n\n",
    "    g = 0.0\n",
    "    l = len(x)\n",
    "    for i in range(0,l):\n",
    "        g += (np.log(comb(pi,x[i+1])) + x[i+1]*np.log(xaj[i]) + (pi-x[i+1])*np.log(1-xaj[i]))\n",
    "    return g+np.log(xa)\n",
    "\n",
    "\n",
    "def classification(test_data, a, aj):\n",
    "    xnum = test_data.shape[0]\n",
    "    fnum = test_data.shape[1]-2\n",
    "    x_test = test_data.loc[:,1:fnum]\n",
    "    p = test_data[fnum+1].tolist()\n",
    "    # y_test = test_data[0]\n",
    "    prelist = []\n",
    "    for i in range(0, xnum):\n",
    "        ex = x_test.iloc[i]\n",
    "        # print i\n",
    "        c1 =  calcm(ex,a[0],aj[0],p[i])\n",
    "        c2 =  calcm(ex,a[1],aj[1],p[i])\n",
    "        if c1<c2:\n",
    "            prelist.append(2)\n",
    "        else:\n",
    "            prelist.append(1)\n",
    "    return prelist\n",
    "\n",
    "def cMatrix(test_data,prelist):\n",
    "    y_test= test_data[0].tolist()\n",
    "    cm = np.zeros((2,2))\n",
    "    print len(y_test)\n",
    "    for i in range(0,len(y_test)):\n",
    "        rl = y_test[i]\n",
    "        pre = prelist[i]\n",
    "        cm[rl-1][pre-1] += 1\n",
    "    return cm\n",
    "\n",
    "# Compute the confusion matrix, precision, recall,F-measure, and accuracy\n",
    "def evalpf(cm):\n",
    "    tp = cm[0][0]\n",
    "    fp = cm[0][1]\n",
    "    fn = cm[1][0]\n",
    "    tn = cm[1][1]\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    Fm = 2*precision*recall/(precision+recall)\n",
    "    return (precision,recall,Fm,accuracy)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data_train = rf('SPECTF.train')\n",
    "    data_test = rf('SPECTF.test')\n",
    "    alfa, alfaj = getParam(data_train)  #(alfa/xnum, alfaj)\n",
    "    print 'Alpha:'\n",
    "    print alfa\n",
    "    print 'Alphaj:'\n",
    "    print alfaj\n",
    "\n",
    "    y_predict = classification(data_test, alfa, alfaj)\n",
    "    cm = cMatrix(data_test,y_predict)\n",
    "    print 'confusion matrix is '\n",
    "    print cm\n",
    "    result = evalpf(cm)\n",
    "    print 'result of precision, recall,F-measure, and accuracy are'\n",
    "    print result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
